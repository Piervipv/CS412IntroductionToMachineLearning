{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe management\n",
    "import pandas as pd             \n",
    "\n",
    "# numerical computation\n",
    "import numpy as np\n",
    "\n",
    "# visualization library\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "sns.set_context(rc={\"font.family\":'sans',\"font.size\":24,\"axes.titlesize\":24,\"axes.labelsize\":24})   \n",
    "\n",
    "\n",
    "# seaborn can generate several warnings, we ignore them\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "#dataset = pd.read_csv('./subdataset.csv')\n",
    "dataset.head() #show the first n instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 1306122\n",
      "number of columns: 3\n"
     ]
    }
   ],
   "source": [
    "#Let's check the dimension of the dataset\n",
    "rows = dataset.shape[0]\n",
    "print(\"number of rows: \" + str(rows))\n",
    "columns = dataset.shape[1]\n",
    "print(\"number of columns: \" + str(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is very big: creating a BagOfWord model and train algorithms on that will be too expensive.\n",
    "Because of the fact that the performance of the classifier will not be a criteria for the project I will take a subSet of the dataset and from now on I will work on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset.to_csv(r'./subdataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 10000\n",
      "number of columns: 3\n"
     ]
    }
   ],
   "source": [
    "#Let's check again the dimension of the dataset\n",
    "rows = dataset.shape[0]\n",
    "print(\"number of rows: \" + str(rows))\n",
    "columns = dataset.shape[1]\n",
    "print(\"number of columns: \" + str(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.21% of instancies are positive\n",
      "93.79% of instancies are negative\n"
     ]
    }
   ],
   "source": [
    "#let's check the percentange of positive and negative examples\n",
    "positive = 0\n",
    "for row in dataset.itertuples():\n",
    "    positive += row.target\n",
    "\n",
    "print(str(positive*100/rows) + \"% of instancies are positive\")\n",
    "print(str(100-positive*100/rows) + \"% of instancies are negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class document:\n",
    "    def __init__(self,words, target):\n",
    "        self.words=words #dictionary of contained words\n",
    "        self.target=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text):\n",
    "    words = text.split()\n",
    "    wordsLowerCase = []\n",
    "    for word in words:\n",
    "        wordsLowerCase.append(word.lower())\n",
    "    return wordsLowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done.\n",
      "10.0% done.\n",
      "20.0% done.\n",
      "30.0% done.\n",
      "40.0% done.\n",
      "50.0% done.\n",
      "60.0% done.\n",
      "70.0% done.\n",
      "80.0% done.\n",
      "90.0% done.\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#let's create a dictionary of dictionary\n",
    "\n",
    "#questionDictionary: qid -> WordDictionary, target\n",
    "#WordDictionary: word_contained_in_given_question -> #number_of_occurencies\n",
    "\n",
    "#for each row:\n",
    "    #take the text and parse it (retrieve the list of contained words and update the vocaubolary of the collection)\n",
    "    #add an entry in the dictionary\n",
    "    \n",
    "questionDictionary = {}\n",
    "vocabulary = set()\n",
    "\n",
    "update = 0\n",
    "\n",
    "for row in dataset.itertuples():\n",
    "    wordDictionary = {}\n",
    "    if (update%1000 == 0):\n",
    "        print(str(round((update*100/rows),2)) + \"% done.\" )\n",
    "    update +=1\n",
    "    \n",
    "    words = parse (row.question_text)\n",
    "    vocabulary.update(words)\n",
    "    \n",
    "    #initialize the wordDictionary\n",
    "    for word in words:\n",
    "        wordDictionary[word] = 0\n",
    "        \n",
    "    #count the occurencies of each word\n",
    "    for word in words:\n",
    "        wordDictionary[word] += 1\n",
    "    \n",
    "    documentInstance = document (wordDictionary, row.target)\n",
    "    questionDictionary[row.qid]= documentInstance\n",
    "    \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the collection there are 21359 distinct words.\n",
      "first then words:\n",
      "['columbia', 'americans,', 'supporting', 'regulation', 'copper', 'rap', 'detox', 'unacademy?', 'someday?', 'dubstep']\n"
     ]
    }
   ],
   "source": [
    "#Let's check the vocabulary\n",
    "print(\"in the collection there are \" + str(len(vocabulary)) + \" distinct words.\" )\n",
    "\n",
    "#print first 10 of them\n",
    "print(\"first then words:\")\n",
    "print(list(vocabulary)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '!\"?', '\"', '\"/proj3/mypipe\"', '\"100%', '\"104\"', '\"200', '\"700000\"', '\"?', '\"a', '\"abiogenesis\"?', '\"age', '\"ai', '\"alice\\'s', '\"all', '\"american', '\"andare', '\"anger', '\"anus', '\"are', '\"arm\"', '\"as', '\"barkha', '\"because', '\"being', '\"beliefs\"?', '\"big', '\"bites\".', '\"black', '\"blibber-blubber\"', '\"bluetooth', '\"bn', '\"bougie\"', '\"bubble', '\"bud,', '\"bundmar\"', '\"bye\"', '\"bytes\"?', '\"c\"', '\"c\",']\n",
      "\n",
      "['2?', '2^x', '2a', '2d', '2examples', '2k18', '2k18?', '2l', '2nd', '2no+o2>2no2?']\n"
     ]
    }
   ],
   "source": [
    "#Let's order alphabetically the vocabulary\n",
    "vocabulary = sorted(list(vocabulary))\n",
    "#Let's explore the vocabulary\n",
    "print(vocabulary[0:40])\n",
    "print()\n",
    "print(vocabulary[990:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the vocabulary contains a lot of elements that are not actually words and this increases by a lot the size.\n",
    "Before building the BagOfWord Model we should apply a better parser to extract only actual words and take off usless words.\n",
    "For now let's continue in this way, further preprocessing will be performed in other notebook (Preprocessing1,..) and the performance of the model from the different BagOfWords models will be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to create a database where the rows are vectors with #columns = size of vocabulary\n",
    "and for each row set the corresponding columns to 1 if the question contains that word, 0 otherwise.\n",
    "\n",
    "i.e.\n",
    "V = {cat, dog, mouse}\n",
    "\n",
    "q1: id = 1234; text = {cat, mouse}; target = 0 .  \n",
    "\n",
    "--> corresponding row: \n",
    "\n",
    "| 1234 (id) | 1 (cat) | 0 (dog) | 1 (mouse) | 0 (target) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numba import jit\n",
    "\n",
    "#@jit\n",
    "def extractRow(qid):\n",
    "    row = []\n",
    "    #row.append(qid)\n",
    "\n",
    "    #bagOfwords=[]\n",
    "    question = questionDictionary[qid]\n",
    "    questionWords = question.words\n",
    "    for word in vocabulary:\n",
    "        #if word in the text of the question:\n",
    "            #bagOfwords.append(1)\n",
    "        #else:\n",
    "            #bagOfwords.append(0)        \n",
    "        try:\n",
    "            #check if the word is contained in the question\n",
    "            row.append(questionWords[word])\n",
    "        except:\n",
    "            #if word is not in the dictionary cach the expeption\n",
    "            #and consider that word is not in that question\n",
    "            row.append(0)\n",
    "    #concatenate\n",
    "    #row += bagOfwords\n",
    "    row.append(question.target)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionIndexDictionary = {}\n",
    "index = 0\n",
    "for qid in questionDictionary.keys():\n",
    "    questionIndexDictionary[qid] = index\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an new Dataframe for the BagOfWordModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsName = []\n",
    "columnsName += vocabulary\n",
    "columnsName.append('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([],columns=columnsName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done.\n",
      "10.0% done.\n",
      "20.0% done.\n",
      "30.0% done.\n",
      "40.0% done.\n",
      "50.0% done.\n",
      "60.0% done.\n",
      "70.0% done.\n",
      "80.0% done.\n",
      "90.0% done.\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# creaimo matrice\n",
    "index = 0\n",
    "for qid in questionDictionary.keys():\n",
    "#for qid in tqdm.tqdm(questionDictionary.keys()):\n",
    "    if (index%1000 == 0):\n",
    "        print(str(round((index*100/rows),2)) + \"% done.\" )\n",
    "    index +=1\n",
    "    \n",
    "    #qid = row.qid\n",
    "    #dataset.append(extractRow(qid))    \n",
    "    df.loc[questionIndexDictionary[qid]] =extractRow(qid)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>!\"?</th>\n",
       "      <th>\"</th>\n",
       "      <th>\"/proj3/mypipe\"</th>\n",
       "      <th>\"100%</th>\n",
       "      <th>\"104\"</th>\n",
       "      <th>\"200</th>\n",
       "      <th>\"700000\"</th>\n",
       "      <th>\"?</th>\n",
       "      <th>\"a</th>\n",
       "      <th>...</th>\n",
       "      <th>“writing”</th>\n",
       "      <th>…</th>\n",
       "      <th>…just</th>\n",
       "      <th>…only</th>\n",
       "      <th>₹</th>\n",
       "      <th>₹15,000</th>\n",
       "      <th>√</th>\n",
       "      <th>√3√3√3√3√3?</th>\n",
       "      <th>❓?</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ! !\"?  \" \"/proj3/mypipe\" \"100% \"104\" \"200 \"700000\" \"? \"a  ...   “writing”  \\\n",
       "0  0   0  0               0     0     0    0        0  0  0  ...           0   \n",
       "1  0   0  0               0     0     0    0        0  0  0  ...           0   \n",
       "2  0   0  0               0     0     0    0        0  0  0  ...           0   \n",
       "3  0   0  0               0     0     0    0        0  0  0  ...           0   \n",
       "4  0   0  0               0     0     0    0        0  0  0  ...           0   \n",
       "\n",
       "   … …just …only  ₹ ₹15,000  √ √3√3√3√3√3? ❓? TARGET  \n",
       "0  0     0     0  0       0  0           0  0      0  \n",
       "1  0     0     0  0       0  0           0  0      0  \n",
       "2  0     0     0  0       0  0           0  0      0  \n",
       "3  0     0     0  0       0  0           0  0      0  \n",
       "4  0     0     0  0       0  0           0  0      0  \n",
       "\n",
       "[5 rows x 21360 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'./BagOfWordDataSet0.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
